{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Project 2: Rossmann Store Sales (Regression)\n",
                "\n",
                "## Objective\n",
                "Predict daily sales for Rossmann stores using historical data.\n",
                "This notebook covers:\n",
                "1. Data Loading\n",
                "2. Exploratory Data Analysis (EDA)\n",
                "3. Preprocessing (Feature Engineering)\n",
                "4. Building a Deep ANN (7-8 Layers)\n",
                "5. Hyperparameter Tuning\n",
                "6. Training and Evaluation\n",
                "7. Saving the Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install -q keras-tuner"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
                "import tensorflow as tf\n",
                "from tensorflow import keras\n",
                "from tensorflow.keras import layers\n",
                "import keras_tuner as kt\n",
                "\n",
                "np.random.seed(42)\n",
                "tf.random.set_seed(42)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Data Loading"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "url = \"https://raw.githubusercontent.com/RPI-DATA/tutorials-intro/master/rossmann-store-sales/rossmann-store-sales/train.csv\"\n",
                "df = pd.read_csv(url, low_memory=False)\n",
                "print(f\"Dataset Shape: {df.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Exploratory Data Analysis (EDA)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Sales Distribution\n",
                "plt.figure(figsize=(10, 5))\n",
                "sns.histplot(df['Sales'], bins=50, kde=True)\n",
                "plt.title('Sales Distribution')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Sales over time (Sample Store)\n",
                "df['Date'] = pd.to_datetime(df['Date'])\n",
                "store_1 = df[df['Store'] == 1].sort_values('Date')\n",
                "\n",
                "plt.figure(figsize=(12, 5))\n",
                "plt.plot(store_1['Date'], store_1['Sales'])\n",
                "plt.title('Sales over Time (Store 1)')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Preprocessing"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Extract Date Features\n",
                "df['Year'] = df['Date'].dt.year\n",
                "df['Month'] = df['Date'].dt.month\n",
                "df['Day'] = df['Date'].dt.day\n",
                "df['DayOfWeek'] = df['Date'].dt.dayofweek\n",
                "\n",
                "# Drop Date and Customers (Customers is not known at prediction time usually, but let's drop it to be safe or keep if we assume we know footfall. Usually we don't know customers. Let's drop it.)\n",
                "df = df.drop(columns=['Date', 'Customers'])\n",
                "\n",
                "# Handle Categorical Variables\n",
                "# StateHoliday, SchoolHoliday are categorical\n",
                "df['StateHoliday'] = df['StateHoliday'].astype(str)\n",
                "\n",
                "le = LabelEncoder()\n",
                "df['StateHoliday'] = le.fit_transform(df['StateHoliday'])\n",
                "\n",
                "# Only use open stores with sales > 0\n",
                "df = df[(df['Open'] == 1) & (df['Sales'] > 0)]\n",
                "\n",
                "# Drop Open column as it's all 1 now\n",
                "df = df.drop(columns=['Open'])\n",
                "\n",
                "print(f\"Processed Shape: {df.shape}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Separate Target\n",
                "X = df.drop(columns=['Sales'])\n",
                "y = df['Sales']\n",
                "\n",
                "# Split Data\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
                "\n",
                "# Scale Data\n",
                "scaler = StandardScaler()\n",
                "X_train_scaled = scaler.fit_transform(X_train)\n",
                "X_test_scaled = scaler.transform(X_test)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4 & 5. Build ANN & Hyperparameter Tuning"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def build_model(hp):\n",
                "    model = keras.Sequential()\n",
                "    model.add(layers.Input(shape=(X_train_scaled.shape[1],)))\n",
                "    \n",
                "    # 7 to 8 Hidden Layers\n",
                "    for i in range(hp.Int('num_layers', 7, 8)):\n",
                "        model.add(layers.Dense(\n",
                "            units=hp.Int(f'units_{i}', min_value=64, max_value=512, step=64),\n",
                "            activation='relu'\n",
                "        ))\n",
                "        model.add(layers.Dropout(hp.Float(f'dropout_{i}', 0.0, 0.3, step=0.1)))\n",
                "        \n",
                "    # Output Layer (Regression)\n",
                "    model.add(layers.Dense(1, activation='linear'))\n",
                "    \n",
                "    model.compile(\n",
                "        optimizer=keras.optimizers.Adam(learning_rate=hp.Float('lr', 1e-4, 1e-2, sampling='log')),\n",
                "        loss='mean_squared_error',\n",
                "        metrics=['mean_absolute_error']\n",
                "    )\n",
                "    return model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "tuner = kt.RandomSearch(\n",
                "    build_model,\n",
                "    objective='val_loss',\n",
                "    max_trials=3,\n",
                "    executions_per_trial=1,\n",
                "    directory='my_dir',\n",
                "    project_name='rossmann_tuning'\n",
                ")\n",
                "\n",
                "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
                "\n",
                "tuner.search(X_train_scaled, y_train, epochs=10, validation_split=0.2, callbacks=[stop_early])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
                "print(f\"Best Layers: {best_hps.get('num_layers')}\")\n",
                "print(f\"Best LR: {best_hps.get('lr')}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Train Best Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model = tuner.hypermodel.build(best_hps)\n",
                "\n",
                "history = model.fit(\n",
                "    X_train_scaled, \n",
                "    y_train, \n",
                "    epochs=100, \n",
                "    validation_split=0.2,\n",
                "    callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)]\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Evaluation & Visualization"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.figure(figsize=(12, 5))\n",
                "plt.plot(history.history['loss'], label='Train Loss')\n",
                "plt.plot(history.history['val_loss'], label='Val Loss')\n",
                "plt.title('Model Loss (MSE)')\n",
                "plt.xlabel('Epoch')\n",
                "plt.ylabel('Loss')\n",
                "plt.legend()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "test_loss, test_mae = model.evaluate(X_test_scaled, y_test)\n",
                "print(f\"Test MSE: {test_loss:.2f}\")\n",
                "print(f\"Test MAE: {test_mae:.2f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Save Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model.save('model_2.h5')\n",
                "print(\"Model saved as model_2.h5\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}